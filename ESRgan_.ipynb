{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52c6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b286565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.10.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'input'    \n",
    "OUTPUT_DIR = 'output' \n",
    "NUM_SAMPLES = 100     \n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 2     # Keep this low due to 8GB VRAM\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "IMG_CHANNELS = 3\n",
    "LR_SHAPE = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "HR_SHAPE = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0cef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator configuration\n",
    "RESIDUAL_BLOCKS = 6 # Number of RRDB blocks (adjust based on VRAM, standard ESRGAN uses ~16-23)\n",
    "GF = 32           # Generator filters\n",
    "\n",
    "# Loss weights\n",
    "LAMBDA_L1 = 1e-2      \n",
    "LAMBDA_PERCEPTUAL = 1.0 \n",
    "LAMBDA_GAN = 5e-3       \n",
    "\n",
    "LEARNING_RATE_G = 1e-4\n",
    "LEARNING_RATE_D = 1e-4\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9830621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CHECKPOINT_DIR = './training_checkpoints_satellite'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b96f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=IMG_CHANNELS)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) # Normalizes to [0, 1]\n",
    "    return image\n",
    "\n",
    "def load_dataset(input_dir, output_dir, num_samples):\n",
    "    input_paths = sorted(glob(os.path.join(input_dir, \"*.jpg\")))[:num_samples]\n",
    "    output_paths = sorted(glob(os.path.join(output_dir, \"*.jpg\")))[:num_samples]\n",
    "\n",
    "    if len(input_paths) == 0 or len(output_paths) == 0:\n",
    "        raise ValueError(\"Input or Output directory is empty or contains no .jpg files.\")\n",
    "    if len(input_paths) != len(output_paths):\n",
    "         raise ValueError(f\"Mismatch in number of files: {len(input_paths)} input vs {len(output_paths)} output.\")\n",
    "\n",
    "    print(f\"Found {len(input_paths)} image pairs.\")\n",
    "\n",
    "    # Create tf.data datasets\n",
    "    input_ds = tf.data.Dataset.from_tensor_slices(input_paths).map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    output_ds = tf.data.Dataset.from_tensor_slices(output_paths).map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Zip datasets\n",
    "    dataset = tf.data.Dataset.zip((input_ds, output_ds))\n",
    "\n",
    "    # Batch, shuffle, and prefetch\n",
    "    dataset = dataset.shuffle(buffer_size=num_samples)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8314edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- ESRGAN Generator (RRDBNet adapted for same input/output size) ---\n",
    "\n",
    "def dense_block(input_tensor, filters):\n",
    "    \"\"\" Basic Dense Block used in RRDB \"\"\"\n",
    "    x1 = layers.Conv2D(filters, kernel_size=3, padding='same')(input_tensor)\n",
    "    x1 = layers.LeakyReLU(alpha=0.2)(x1)\n",
    "    x1_concat = layers.concatenate([input_tensor, x1], axis=-1)\n",
    "\n",
    "    x2 = layers.Conv2D(filters, kernel_size=3, padding='same')(x1_concat)\n",
    "    x2 = layers.LeakyReLU(alpha=0.2)(x2)\n",
    "    x2_concat = layers.concatenate([input_tensor, x1, x2], axis=-1)\n",
    "\n",
    "    x3 = layers.Conv2D(filters, kernel_size=3, padding='same')(x2_concat)\n",
    "    x3 = layers.LeakyReLU(alpha=0.2)(x3)\n",
    "    x3_concat = layers.concatenate([input_tensor, x1, x2, x3], axis=-1)\n",
    "\n",
    "    x4 = layers.Conv2D(filters, kernel_size=3, padding='same')(x3_concat)\n",
    "    x4 = layers.LeakyReLU(alpha=0.2)(x4)\n",
    "    x4_concat = layers.concatenate([input_tensor, x1, x2, x3, x4], axis=-1)\n",
    "\n",
    "    x5 = layers.Conv2D(filters, kernel_size=3, padding='same')(x4_concat)\n",
    "    # No final activation in the dense block path, only within RRDB residual\n",
    "\n",
    "    # Scale output before adding residual\n",
    "    x5 = layers.Lambda(lambda x: x * 0.2)(x5)\n",
    "    return x5\n",
    "\n",
    "\n",
    "def rrdb(input_tensor, filters):\n",
    "    \"\"\" Residual-in-Residual Dense Block \"\"\"\n",
    "    x = dense_block(input_tensor, filters)\n",
    "    x = layers.add([x, input_tensor]) # Residual connection within RRDB\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_generator(input_shape, num_residual_blocks=RESIDUAL_BLOCKS, gf=GF):\n",
    "    \"\"\" Builds the Generator network \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial Convolution\n",
    "    x_feat = layers.Conv2D(gf, kernel_size=3, padding='same')(inputs)\n",
    "    x = x_feat # Store for later skip connection\n",
    "\n",
    "    # RRDB Blocks\n",
    "    for _ in range(num_residual_blocks):\n",
    "        x = rrdb(x, gf)\n",
    "\n",
    "    # Post-RRDB Convolution\n",
    "    x = layers.Conv2D(gf, kernel_size=3, padding='same')(x)\n",
    "    x = layers.add([x, x_feat]) # Skip connection over RRDBs\n",
    "\n",
    "    # --- NO UPSAMPLING NEEDED as input/output are same size ---\n",
    "    # If upsampling were needed, it would go here:\n",
    "    # x = layers.UpSampling2D(size=2, interpolation='nearest')(x)\n",
    "    # x = layers.Conv2D(gf, kernel_size=3, padding='same')(x)\n",
    "    # x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    # x = layers.UpSampling2D(size=2, interpolation='nearest')(x)\n",
    "    # x = layers.Conv2D(gf, kernel_size=3, padding='same')(x)\n",
    "    # x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Final Output Layers\n",
    "    x = layers.Conv2D(gf, kernel_size=3, padding='same')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    outputs = layers.Conv2D(IMG_CHANNELS, kernel_size=3, padding='same', activation='sigmoid')(x) # Sigmoid for [0, 1] output\n",
    "\n",
    "    return keras.Model(inputs, outputs, name='generator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c130d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Discriminator (VGG-style) ---\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "    \"\"\" Builds the Discriminator network \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same')(inputs)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=2, padding='same')(x) # Downsample\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=2, padding='same')(x) # Downsample\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, kernel_size=3, strides=2, padding='same')(x) # Downsample\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(512, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(512, kernel_size=3, strides=2, padding='same')(x) # Downsample\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1024)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    outputs = layers.Dense(1)(x) # Output logits (no activation)\n",
    "\n",
    "    return keras.Model(inputs, outputs, name='discriminator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1adcc8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Perceptual Loss (VGG19) ---\n",
    "\n",
    "# Using mean absolute error for VGG loss (can also use MSE)\n",
    "vgg_loss_object = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "def build_vgg():\n",
    "    \"\"\" Build VGG19 model for perceptual loss \"\"\"\n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape=HR_SHAPE)\n",
    "    vgg.trainable = False\n",
    "    # Use features from a high-level layer (e.g., block5_conv4)\n",
    "    output_layer = vgg.get_layer('block5_conv4').output\n",
    "    model = tf.keras.Model(vgg.input, output_layer)\n",
    "    return model\n",
    "\n",
    "vgg = build_vgg()\n",
    "\n",
    "def perceptual_loss(hr_true, sr_fake):\n",
    "    hr_true_vgg = vgg(tf.keras.applications.vgg19.preprocess_input(hr_true * 255.)) # VGG expects 0-255 input\n",
    "    sr_fake_vgg = vgg(tf.keras.applications.vgg19.preprocess_input(sr_fake * 255.))\n",
    "    return vgg_loss_object(hr_true_vgg, sr_fake_vgg)\n",
    "\n",
    "# --- Other Losses ---\n",
    "binary_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True) # For Adversarial Loss\n",
    "mae_loss = tf.keras.losses.MeanAbsoluteError() # For L1 Pixel Loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb6c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Optimizers ---\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_G, beta_1=BETA_1, beta_2=BETA_2)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_D, beta_1=BETA_1, beta_2=BETA_2)\n",
    "\n",
    "# --- Build Models ---\n",
    "generator = build_generator(LR_SHAPE)\n",
    "discriminator = build_discriminator(HR_SHAPE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "573c9cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 32  896         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 32  9248        ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 256, 256, 32  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256, 256, 64  0           ['conv2d[0][0]',                 \n",
      "                                )                                 'leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 256, 32  18464       ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 256, 256, 32  0           ['conv2d_2[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256, 256, 96  0           ['conv2d[0][0]',                 \n",
      "                                )                                 'leaky_re_lu[0][0]',            \n",
      "                                                                  'leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 256, 256, 32  27680       ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 256, 256, 32  0           ['conv2d_3[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 12  0           ['conv2d[0][0]',                 \n",
      "                                8)                                'leaky_re_lu[0][0]',            \n",
      "                                                                  'leaky_re_lu_1[0][0]',          \n",
      "                                                                  'leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 256, 256, 32  36896       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 256, 256, 32  0           ['conv2d_4[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 16  0           ['conv2d[0][0]',                 \n",
      "                                0)                                'leaky_re_lu[0][0]',            \n",
      "                                                                  'leaky_re_lu_1[0][0]',          \n",
      "                                                                  'leaky_re_lu_2[0][0]',          \n",
      "                                                                  'leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 256, 256, 32  46112       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 256, 256, 32  0           ['conv2d_5[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 256, 256, 32  0           ['lambda[0][0]',                 \n",
      "                                )                                 'conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 256, 256, 32  9248        ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 256, 256, 32  0           ['conv2d_6[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 256, 256, 64  0           ['add[0][0]',                    \n",
      "                                )                                 'leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 256, 256, 32  18464       ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 256, 256, 32  0           ['conv2d_7[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 256, 256, 96  0           ['add[0][0]',                    \n",
      "                                )                                 'leaky_re_lu_4[0][0]',          \n",
      "                                                                  'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 256, 256, 32  27680       ['concatenate_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 256, 256, 32  0           ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 256, 256, 12  0           ['add[0][0]',                    \n",
      "                                8)                                'leaky_re_lu_4[0][0]',          \n",
      "                                                                  'leaky_re_lu_5[0][0]',          \n",
      "                                                                  'leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 256, 256, 32  36896       ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 256, 256, 32  0           ['conv2d_9[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256, 256, 16  0           ['add[0][0]',                    \n",
      "                                0)                                'leaky_re_lu_4[0][0]',          \n",
      "                                                                  'leaky_re_lu_5[0][0]',          \n",
      "                                                                  'leaky_re_lu_6[0][0]',          \n",
      "                                                                  'leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 256, 256, 32  46112       ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 256, 256, 32  0           ['conv2d_10[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 256, 256, 32  0           ['lambda_1[0][0]',               \n",
      "                                )                                 'add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 256, 256, 32  9248        ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 256, 256, 32  0           ['conv2d_11[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 256, 256, 64  0           ['add_1[0][0]',                  \n",
      "                                )                                 'leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 256, 256, 32  18464       ['concatenate_8[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 256, 256, 32  0           ['conv2d_12[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 256, 256, 96  0           ['add_1[0][0]',                  \n",
      "                                )                                 'leaky_re_lu_8[0][0]',          \n",
      "                                                                  'leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 256, 256, 32  27680       ['concatenate_9[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_13[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 256, 256, 12  0           ['add_1[0][0]',                  \n",
      "                                8)                                'leaky_re_lu_8[0][0]',          \n",
      "                                                                  'leaky_re_lu_9[0][0]',          \n",
      "                                                                  'leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 256, 256, 32  36896       ['concatenate_10[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_14[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 256, 256, 16  0           ['add_1[0][0]',                  \n",
      "                                0)                                'leaky_re_lu_8[0][0]',          \n",
      "                                                                  'leaky_re_lu_9[0][0]',          \n",
      "                                                                  'leaky_re_lu_10[0][0]',         \n",
      "                                                                  'leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 256, 256, 32  46112       ['concatenate_11[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 256, 256, 32  0           ['conv2d_15[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 256, 256, 32  0           ['lambda_2[0][0]',               \n",
      "                                )                                 'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 256, 32  9248        ['add_2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 256, 256, 64  0           ['add_2[0][0]',                  \n",
      "                                )                                 'leaky_re_lu_12[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 256, 256, 32  18464       ['concatenate_12[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_17[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 256, 256, 96  0           ['add_2[0][0]',                  \n",
      "                                )                                 'leaky_re_lu_12[0][0]',         \n",
      "                                                                  'leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 256, 32  27680       ['concatenate_13[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_18[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 256, 256, 12  0           ['add_2[0][0]',                  \n",
      "                                8)                                'leaky_re_lu_12[0][0]',         \n",
      "                                                                  'leaky_re_lu_13[0][0]',         \n",
      "                                                                  'leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 256, 256, 32  36896       ['concatenate_14[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_19[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 256, 256, 16  0           ['add_2[0][0]',                  \n",
      "                                0)                                'leaky_re_lu_12[0][0]',         \n",
      "                                                                  'leaky_re_lu_13[0][0]',         \n",
      "                                                                  'leaky_re_lu_14[0][0]',         \n",
      "                                                                  'leaky_re_lu_15[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 256, 256, 32  46112       ['concatenate_15[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 256, 256, 32  0           ['conv2d_20[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 256, 256, 32  0           ['lambda_3[0][0]',               \n",
      "                                )                                 'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 256, 256, 32  9248        ['add_3[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_21[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 256, 256, 64  0           ['add_3[0][0]',                  \n",
      "                                )                                 'leaky_re_lu_16[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 256, 256, 32  18464       ['concatenate_16[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_22[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 256, 256, 96  0           ['add_3[0][0]',                  \n",
      "                                )                                 'leaky_re_lu_16[0][0]',         \n",
      "                                                                  'leaky_re_lu_17[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 256, 256, 32  27680       ['concatenate_17[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_23[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 256, 256, 12  0           ['add_3[0][0]',                  \n",
      "                                8)                                'leaky_re_lu_16[0][0]',         \n",
      "                                                                  'leaky_re_lu_17[0][0]',         \n",
      "                                                                  'leaky_re_lu_18[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 256, 256, 32  36896       ['concatenate_18[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_24[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 256, 256, 16  0           ['add_3[0][0]',                  \n",
      "                                0)                                'leaky_re_lu_16[0][0]',         \n",
      "                                                                  'leaky_re_lu_17[0][0]',         \n",
      "                                                                  'leaky_re_lu_18[0][0]',         \n",
      "                                                                  'leaky_re_lu_19[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 256, 256, 32  46112       ['concatenate_19[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 256, 256, 32  0           ['conv2d_25[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 256, 256, 32  0           ['lambda_4[0][0]',               \n",
      "                                )                                 'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 256, 256, 32  9248        ['add_4[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_26[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 256, 256, 64  0           ['add_4[0][0]',                  \n",
      "                                )                                 'leaky_re_lu_20[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 256, 256, 32  18464       ['concatenate_20[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_27[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 256, 256, 96  0           ['add_4[0][0]',                  \n",
      "                                )                                 'leaky_re_lu_20[0][0]',         \n",
      "                                                                  'leaky_re_lu_21[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 256, 256, 32  27680       ['concatenate_21[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_28[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 256, 256, 12  0           ['add_4[0][0]',                  \n",
      "                                8)                                'leaky_re_lu_20[0][0]',         \n",
      "                                                                  'leaky_re_lu_21[0][0]',         \n",
      "                                                                  'leaky_re_lu_22[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 256, 256, 32  36896       ['concatenate_22[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_29[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 256, 256, 16  0           ['add_4[0][0]',                  \n",
      "                                0)                                'leaky_re_lu_20[0][0]',         \n",
      "                                                                  'leaky_re_lu_21[0][0]',         \n",
      "                                                                  'leaky_re_lu_22[0][0]',         \n",
      "                                                                  'leaky_re_lu_23[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 256, 256, 32  46112       ['concatenate_23[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 256, 256, 32  0           ['conv2d_30[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 256, 256, 32  0           ['lambda_5[0][0]',               \n",
      "                                )                                 'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 256, 256, 32  9248        ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 256, 256, 32  0           ['conv2d_31[0][0]',              \n",
      "                                )                                 'conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 256, 256, 32  9248        ['add_6[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_24 (LeakyReLU)     (None, 256, 256, 32  0           ['conv2d_32[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 256, 256, 3)  867         ['leaky_re_lu_24[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 850,659\n",
      "Trainable params: 850,659\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ba5c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 128, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128, 128)    512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_27 (LeakyReLU)  (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_28 (LeakyReLU)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64, 64, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 32, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_30 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32, 32, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_31 (LeakyReLU)  (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 16, 16, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_32 (LeakyReLU)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              134218752 \n",
      "                                                                 \n",
      " leaky_re_lu_33 (LeakyReLU)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,912,577\n",
      "Trainable params: 138,908,865\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a62221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Checkpointing ---\n",
    "checkpoint_prefix = os.path.join(CHECKPOINT_DIR, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e25ab8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Training Step ---\n",
    "@tf.function\n",
    "def train_step(input_img, target_img):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generate enhanced image\n",
    "        sr_img = generator(input_img, training=True)\n",
    "\n",
    "        # Discriminator output for real and fake images\n",
    "        real_output = discriminator(target_img, training=True)\n",
    "        fake_output = discriminator(sr_img, training=True)\n",
    "\n",
    "        # --- Calculate Losses ---\n",
    "\n",
    "        # Generator Adversarial Loss (wants discriminator to think fake is real)\n",
    "        gen_gan_loss = binary_cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "        # Perceptual Loss (VGG)\n",
    "        perc_loss = perceptual_loss(target_img, sr_img)\n",
    "\n",
    "        # Pixel Loss (L1)\n",
    "        l1_loss = mae_loss(target_img, sr_img)\n",
    "\n",
    "        # Total Generator Loss\n",
    "        total_gen_loss = (LAMBDA_GAN * gen_gan_loss +\n",
    "                          LAMBDA_PERCEPTUAL * perc_loss +\n",
    "                          LAMBDA_L1 * l1_loss)\n",
    "\n",
    "        # Discriminator Loss\n",
    "        real_loss = binary_cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = binary_cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        total_disc_loss = real_loss + fake_loss\n",
    "\n",
    "    # Calculate Gradients\n",
    "    generator_gradients = gen_tape.gradient(total_gen_loss, generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(total_disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Apply Gradients\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "\n",
    "    return total_gen_loss, total_disc_loss, l1_loss, perc_loss, gen_gan_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42facebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Image Generation for Visualization ---\n",
    "def generate_and_save_images(model, test_input_batch, epoch):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(\"./generated_images\", exist_ok=True)\n",
    "\n",
    "    predictions = model(test_input_batch, training=False) # Use first few images from the batch\n",
    "\n",
    "    plt.figure(figsize=(10, 5 * predictions.shape[0])) # Adjust figure size based on batch size used for sampling\n",
    "\n",
    "    num_display = min(predictions.shape[0], 4) # Display up to 4 images\n",
    "\n",
    "    for i in range(num_display):\n",
    "        plt.subplot(num_display, 2, 2*i + 1)\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.imshow(test_input_batch[i]) # Assumes input is [0, 1]\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_display, 2, 2*i + 2)\n",
    "        plt.title(\"Generated Image\")\n",
    "        plt.imshow(predictions[i]) # Assumes prediction is [0, 1]\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./generated_images/image_at_epoch_{epoch+1:04d}.png')\n",
    "    print(f\"Generated sample image saved for epoch {epoch+1}\")\n",
    "    plt.close() # Close the plot to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d2d72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Training Loop ---\n",
    "def train(dataset, epochs):\n",
    "    print(f\"\\n--- Starting Training for {epochs} Epochs ---\")\n",
    "    print(f\"Dataset size: {NUM_SAMPLES} images\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"Batches per epoch: {len(dataset)}\") # tf.data lengths might be approximate before first iteration\n",
    "\n",
    "    # Try restoring checkpoint\n",
    "    ckpt_status = checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINT_DIR))\n",
    "    if tf.train.latest_checkpoint(CHECKPOINT_DIR):\n",
    "         print(f\"Checkpoint restored from {tf.train.latest_checkpoint(CHECKPOINT_DIR)}\")\n",
    "         # ckpt_status.assert_consumed() # Optional: check if all variables were restored\n",
    "    else:\n",
    "         print(\"Initializing from scratch.\")\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        epoch_gen_loss = 0\n",
    "        epoch_disc_loss = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        for batch_idx, (input_batch, target_batch) in enumerate(dataset):\n",
    "            gen_loss, disc_loss, l1, perc, gan = train_step(input_batch, target_batch)\n",
    "\n",
    "            epoch_gen_loss += gen_loss\n",
    "            epoch_disc_loss += disc_loss\n",
    "            batch_count += 1\n",
    "\n",
    "            if batch_idx % 10 == 0: # Print progress every 10 batches\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{len(dataset)}, \"\n",
    "                      f\"Gen Loss: {gen_loss:.4f} (L1: {l1:.4f}, Perc: {perc:.4f}, GAN: {gan:.4f}), \"\n",
    "                      f\"Disc Loss: {disc_loss:.4f}\")\n",
    "\n",
    "        # End of Epoch\n",
    "        avg_gen_loss = epoch_gen_loss / batch_count\n",
    "        avg_disc_loss = epoch_disc_loss / batch_count\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"Time: {epoch_time:.2f}s\")\n",
    "        print(f\"Average Generator Loss: {avg_gen_loss:.4f}\")\n",
    "        print(f\"Average Discriminator Loss: {avg_disc_loss:.4f}\")\n",
    "\n",
    "        # Save checkpoint every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            print(f\"Checkpoint saved for epoch {epoch+1}\")\n",
    "\n",
    "        # Optional: Generate and save a sample image\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "             generate_and_save_images(generator, next(iter(dataset))[0], epoch) # Use first batch input\n",
    "\n",
    "\n",
    "    print(\"\\n--- Training Finished ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81e7310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 image pairs.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(INPUT_DIR, OUTPUT_DIR, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "854f4e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training for 50 Epochs ---\n",
      "Dataset size: 100 images\n",
      "Batch size: 2\n",
      "Batches per epoch: 50\n",
      "Initializing from scratch.\n",
      "Epoch 1/50, Batch 1/50, Gen Loss: 0.7291 (L1: 0.2474, Perc: 0.7218, GAN: 0.9531), Disc Loss: 1.4868\n",
      "Epoch 1/50, Batch 11/50, Gen Loss: 1.1974 (L1: 0.2812, Perc: 0.7200, GAN: 94.9178), Disc Loss: 0.0000\n",
      "Epoch 1/50, Batch 21/50, Gen Loss: 1.6395 (L1: 0.3781, Perc: 0.7835, GAN: 170.4381), Disc Loss: 0.0000\n",
      "Epoch 1/50, Batch 31/50, Gen Loss: 1.1698 (L1: 0.3719, Perc: 0.5640, GAN: 120.4117), Disc Loss: 0.0000\n",
      "Epoch 1/50, Batch 41/50, Gen Loss: 0.8428 (L1: 0.2447, Perc: 0.8403, GAN: 0.0000), Disc Loss: 27.8888\n",
      "\n",
      "Epoch 1 Summary:\n",
      "Time: 22.78s\n",
      "Average Generator Loss: 1.0961\n",
      "Average Discriminator Loss: 5.1689\n",
      "Epoch 2/50, Batch 1/50, Gen Loss: 0.8708 (L1: 0.2661, Perc: 0.7771, GAN: 18.2128), Disc Loss: 13.5819\n",
      "Epoch 2/50, Batch 11/50, Gen Loss: 0.7134 (L1: 0.3688, Perc: 0.5723, GAN: 27.4855), Disc Loss: 5.8020\n",
      "Epoch 2/50, Batch 21/50, Gen Loss: 1.0176 (L1: 0.3137, Perc: 0.7823, GAN: 46.4373), Disc Loss: 0.0926\n",
      "Epoch 2/50, Batch 31/50, Gen Loss: 0.6827 (L1: 0.2140, Perc: 0.6522, GAN: 5.6561), Disc Loss: 0.0085\n",
      "Epoch 2/50, Batch 41/50, Gen Loss: 0.4401 (L1: 0.1507, Perc: 0.4386, GAN: 0.0000), Disc Loss: 17.2134\n",
      "\n",
      "Epoch 2 Summary:\n",
      "Time: 15.31s\n",
      "Average Generator Loss: 0.7260\n",
      "Average Discriminator Loss: 4.6634\n",
      "Epoch 3/50, Batch 1/50, Gen Loss: 1.0654 (L1: 0.1760, Perc: 0.7680, GAN: 59.1298), Disc Loss: 5.0681\n",
      "Epoch 3/50, Batch 11/50, Gen Loss: 0.8102 (L1: 0.3220, Perc: 0.5167, GAN: 58.0445), Disc Loss: 11.8026\n",
      "Epoch 3/50, Batch 21/50, Gen Loss: 0.9013 (L1: 0.3518, Perc: 0.8010, GAN: 19.3605), Disc Loss: 0.0000\n",
      "Epoch 3/50, Batch 31/50, Gen Loss: 1.0510 (L1: 0.2459, Perc: 0.8665, GAN: 36.4092), Disc Loss: 0.4886\n",
      "Epoch 3/50, Batch 41/50, Gen Loss: 0.6933 (L1: 0.1612, Perc: 0.4597, GAN: 46.3978), Disc Loss: 17.4158\n",
      "\n",
      "Epoch 3 Summary:\n",
      "Time: 15.34s\n",
      "Average Generator Loss: 0.7413\n",
      "Average Discriminator Loss: 6.6634\n",
      "Epoch 4/50, Batch 1/50, Gen Loss: 0.6282 (L1: 0.2126, Perc: 0.6190, GAN: 1.4130), Disc Loss: 8.5261\n",
      "Epoch 4/50, Batch 11/50, Gen Loss: 0.8060 (L1: 0.2197, Perc: 0.6120, GAN: 38.3641), Disc Loss: 9.3765\n",
      "Epoch 4/50, Batch 21/50, Gen Loss: 0.9189 (L1: 0.2288, Perc: 0.6419, GAN: 54.9477), Disc Loss: 3.5092\n",
      "Epoch 4/50, Batch 31/50, Gen Loss: 0.6099 (L1: 0.3475, Perc: 0.4953, GAN: 22.2211), Disc Loss: 0.0662\n",
      "Epoch 4/50, Batch 41/50, Gen Loss: 0.7096 (L1: 0.3085, Perc: 0.6288, GAN: 15.5362), Disc Loss: 1.3831\n",
      "\n",
      "Epoch 4 Summary:\n",
      "Time: 15.33s\n",
      "Average Generator Loss: 0.7435\n",
      "Average Discriminator Loss: 4.0271\n",
      "Epoch 5/50, Batch 1/50, Gen Loss: 0.7468 (L1: 0.2243, Perc: 0.6744, GAN: 14.0314), Disc Loss: 0.0000\n",
      "Epoch 5/50, Batch 11/50, Gen Loss: 0.9728 (L1: 0.2591, Perc: 0.7621, GAN: 41.6290), Disc Loss: 0.9950\n",
      "Epoch 5/50, Batch 21/50, Gen Loss: 1.0221 (L1: 0.4855, Perc: 0.9581, GAN: 11.8245), Disc Loss: 0.1451\n",
      "Epoch 5/50, Batch 31/50, Gen Loss: 0.5871 (L1: 0.3864, Perc: 0.5555, GAN: 5.5519), Disc Loss: 1.6680\n",
      "Epoch 5/50, Batch 41/50, Gen Loss: 0.5173 (L1: 0.3364, Perc: 0.4153, GAN: 19.7401), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 5 Summary:\n",
      "Time: 15.33s\n",
      "Average Generator Loss: 0.7043\n",
      "Average Discriminator Loss: 3.4433\n",
      "Checkpoint saved for epoch 5\n",
      "Generated sample image saved for epoch 5\n",
      "Epoch 6/50, Batch 1/50, Gen Loss: 0.9464 (L1: 0.3333, Perc: 0.8238, GAN: 23.8541), Disc Loss: 0.4432\n",
      "Epoch 6/50, Batch 11/50, Gen Loss: 0.5807 (L1: 0.2946, Perc: 0.5221, GAN: 11.1218), Disc Loss: 1.6779\n",
      "Epoch 6/50, Batch 21/50, Gen Loss: 0.5769 (L1: 0.3686, Perc: 0.5294, GAN: 8.7626), Disc Loss: 0.0007\n",
      "Epoch 6/50, Batch 31/50, Gen Loss: 0.6629 (L1: 0.3854, Perc: 0.6354, GAN: 4.7253), Disc Loss: 0.7595\n",
      "Epoch 6/50, Batch 41/50, Gen Loss: 0.7154 (L1: 0.3541, Perc: 0.6397, GAN: 14.4220), Disc Loss: 0.0031\n",
      "\n",
      "Epoch 6 Summary:\n",
      "Time: 15.29s\n",
      "Average Generator Loss: 0.7273\n",
      "Average Discriminator Loss: 0.2447\n",
      "Epoch 7/50, Batch 1/50, Gen Loss: 0.7962 (L1: 0.3109, Perc: 0.6428, GAN: 30.0541), Disc Loss: 0.0000\n",
      "Epoch 7/50, Batch 11/50, Gen Loss: 0.8963 (L1: 0.3857, Perc: 0.8259, GAN: 13.2968), Disc Loss: 0.0000\n",
      "Epoch 7/50, Batch 21/50, Gen Loss: 1.0755 (L1: 0.4544, Perc: 0.9335, GAN: 27.4825), Disc Loss: 0.0844\n",
      "Epoch 7/50, Batch 31/50, Gen Loss: 0.5576 (L1: 0.3045, Perc: 0.5026, GAN: 10.3992), Disc Loss: 0.1753\n",
      "Epoch 7/50, Batch 41/50, Gen Loss: 0.7972 (L1: 0.3358, Perc: 0.7234, GAN: 14.0989), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 7 Summary:\n",
      "Time: 14.65s\n",
      "Average Generator Loss: 0.7743\n",
      "Average Discriminator Loss: 0.0847\n",
      "Epoch 8/50, Batch 1/50, Gen Loss: 0.9207 (L1: 0.3129, Perc: 0.7811, GAN: 27.2873), Disc Loss: 0.0000\n",
      "Epoch 8/50, Batch 11/50, Gen Loss: 0.6537 (L1: 0.2973, Perc: 0.4566, GAN: 38.8260), Disc Loss: 0.0000\n",
      "Epoch 8/50, Batch 21/50, Gen Loss: 1.1651 (L1: 0.4911, Perc: 1.0210, GAN: 27.8487), Disc Loss: 0.0000\n",
      "Epoch 8/50, Batch 31/50, Gen Loss: 0.7078 (L1: 0.3816, Perc: 0.6423, GAN: 12.3419), Disc Loss: 0.0001\n",
      "Epoch 8/50, Batch 41/50, Gen Loss: 0.6013 (L1: 0.3271, Perc: 0.4630, GAN: 26.9929), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 8 Summary:\n",
      "Time: 15.18s\n",
      "Average Generator Loss: 0.8010\n",
      "Average Discriminator Loss: 0.0009\n",
      "Epoch 9/50, Batch 1/50, Gen Loss: 0.6422 (L1: 0.3150, Perc: 0.5033, GAN: 27.1575), Disc Loss: 0.0000\n",
      "Epoch 9/50, Batch 11/50, Gen Loss: 0.8103 (L1: 0.3362, Perc: 0.6303, GAN: 35.3328), Disc Loss: 0.0000\n",
      "Epoch 9/50, Batch 21/50, Gen Loss: 0.7100 (L1: 0.3715, Perc: 0.6141, GAN: 18.4421), Disc Loss: 0.0000\n",
      "Epoch 9/50, Batch 31/50, Gen Loss: 0.9105 (L1: 0.4090, Perc: 0.8447, GAN: 12.3336), Disc Loss: 0.0039\n",
      "Epoch 9/50, Batch 41/50, Gen Loss: 0.9113 (L1: 0.4443, Perc: 0.8270, GAN: 15.9613), Disc Loss: 0.0001\n",
      "\n",
      "Epoch 9 Summary:\n",
      "Time: 15.38s\n",
      "Average Generator Loss: 0.7998\n",
      "Average Discriminator Loss: 0.0637\n",
      "Epoch 10/50, Batch 1/50, Gen Loss: 0.6122 (L1: 0.3502, Perc: 0.4833, GAN: 25.0879), Disc Loss: 0.0009\n",
      "Epoch 10/50, Batch 11/50, Gen Loss: 1.0099 (L1: 0.4685, Perc: 0.8591, GAN: 29.2392), Disc Loss: 0.0003\n",
      "Epoch 10/50, Batch 21/50, Gen Loss: 0.5878 (L1: 0.4632, Perc: 0.5521, GAN: 6.2151), Disc Loss: 7.8904\n",
      "Epoch 10/50, Batch 31/50, Gen Loss: 0.8329 (L1: 0.4020, Perc: 0.6774, GAN: 30.2928), Disc Loss: 0.0000\n",
      "Epoch 10/50, Batch 41/50, Gen Loss: 0.7181 (L1: 0.3652, Perc: 0.6033, GAN: 22.2305), Disc Loss: 0.0066\n",
      "\n",
      "Epoch 10 Summary:\n",
      "Time: 15.44s\n",
      "Average Generator Loss: 0.7642\n",
      "Average Discriminator Loss: 1.1395\n",
      "Checkpoint saved for epoch 10\n",
      "Generated sample image saved for epoch 10\n",
      "Epoch 11/50, Batch 1/50, Gen Loss: 0.8929 (L1: 0.4773, Perc: 0.7098, GAN: 35.6535), Disc Loss: 0.0000\n",
      "Epoch 11/50, Batch 11/50, Gen Loss: 0.7876 (L1: 0.4605, Perc: 0.6218, GAN: 32.2403), Disc Loss: 0.0000\n",
      "Epoch 11/50, Batch 21/50, Gen Loss: 0.6412 (L1: 0.4408, Perc: 0.4895, GAN: 29.4641), Disc Loss: 0.3219\n",
      "Epoch 11/50, Batch 31/50, Gen Loss: 0.7120 (L1: 0.4187, Perc: 0.5796, GAN: 25.6520), Disc Loss: 0.2066\n",
      "Epoch 11/50, Batch 41/50, Gen Loss: 0.5791 (L1: 0.3547, Perc: 0.4567, GAN: 23.7757), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 11 Summary:\n",
      "Time: 15.47s\n",
      "Average Generator Loss: 0.7120\n",
      "Average Discriminator Loss: 1.5526\n",
      "Epoch 12/50, Batch 1/50, Gen Loss: 0.7960 (L1: 0.4390, Perc: 0.6167, GAN: 34.9904), Disc Loss: 0.0023\n",
      "Epoch 12/50, Batch 11/50, Gen Loss: 0.6823 (L1: 0.4140, Perc: 0.5169, GAN: 32.2470), Disc Loss: 0.0000\n",
      "Epoch 12/50, Batch 21/50, Gen Loss: 0.5503 (L1: 0.3483, Perc: 0.5071, GAN: 7.9541), Disc Loss: 2.9039\n",
      "Epoch 12/50, Batch 31/50, Gen Loss: 0.6897 (L1: 0.3389, Perc: 0.5609, GAN: 25.0663), Disc Loss: 0.0000\n",
      "Epoch 12/50, Batch 41/50, Gen Loss: 0.9370 (L1: 0.4394, Perc: 0.8527, GAN: 15.9721), Disc Loss: 4.1912\n",
      "\n",
      "Epoch 12 Summary:\n",
      "Time: 15.40s\n",
      "Average Generator Loss: 0.7291\n",
      "Average Discriminator Loss: 2.5014\n",
      "Epoch 13/50, Batch 1/50, Gen Loss: 0.9985 (L1: 0.4566, Perc: 0.8190, GAN: 35.0018), Disc Loss: 0.0000\n",
      "Epoch 13/50, Batch 11/50, Gen Loss: 0.4873 (L1: 0.3668, Perc: 0.4173, GAN: 13.2598), Disc Loss: 0.0008\n",
      "Epoch 13/50, Batch 21/50, Gen Loss: 0.8504 (L1: 0.4362, Perc: 0.7165, GAN: 25.9102), Disc Loss: 0.0000\n",
      "Epoch 13/50, Batch 31/50, Gen Loss: 0.5785 (L1: 0.4429, Perc: 0.5735, GAN: 0.1262), Disc Loss: 12.1827\n",
      "Epoch 13/50, Batch 41/50, Gen Loss: 0.9069 (L1: 0.3342, Perc: 0.6667, GAN: 47.3816), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 13 Summary:\n",
      "Time: 15.24s\n",
      "Average Generator Loss: 0.7309\n",
      "Average Discriminator Loss: 1.2556\n",
      "Epoch 14/50, Batch 1/50, Gen Loss: 0.7361 (L1: 0.3131, Perc: 0.6006, GAN: 26.4809), Disc Loss: 0.0000\n",
      "Epoch 14/50, Batch 11/50, Gen Loss: 0.8057 (L1: 0.3558, Perc: 0.4772, GAN: 64.9911), Disc Loss: 3.8690\n",
      "Epoch 14/50, Batch 21/50, Gen Loss: 0.5750 (L1: 0.3819, Perc: 0.5696, GAN: 0.3257), Disc Loss: 1.7146\n",
      "Epoch 14/50, Batch 31/50, Gen Loss: 0.6838 (L1: 0.3439, Perc: 0.5425, GAN: 27.5758), Disc Loss: 3.7705\n",
      "Epoch 14/50, Batch 41/50, Gen Loss: 0.5249 (L1: 0.4248, Perc: 0.4234, GAN: 19.4423), Disc Loss: 0.0344\n",
      "\n",
      "Epoch 14 Summary:\n",
      "Time: 14.25s\n",
      "Average Generator Loss: 0.7205\n",
      "Average Discriminator Loss: 2.8681\n",
      "Epoch 15/50, Batch 1/50, Gen Loss: 0.7709 (L1: 0.3058, Perc: 0.5512, GAN: 43.3332), Disc Loss: 0.0000\n",
      "Epoch 15/50, Batch 11/50, Gen Loss: 0.7358 (L1: 0.3198, Perc: 0.6413, GAN: 18.2499), Disc Loss: 0.6184\n",
      "Epoch 15/50, Batch 21/50, Gen Loss: 0.8666 (L1: 0.2647, Perc: 0.8168, GAN: 9.4379), Disc Loss: 0.0001\n",
      "Epoch 15/50, Batch 31/50, Gen Loss: 0.6338 (L1: 0.1921, Perc: 0.5107, GAN: 24.2219), Disc Loss: 0.0000\n",
      "Epoch 15/50, Batch 41/50, Gen Loss: 0.7662 (L1: 0.2319, Perc: 0.6412, GAN: 24.5441), Disc Loss: 6.4509\n",
      "\n",
      "Epoch 15 Summary:\n",
      "Time: 15.31s\n",
      "Average Generator Loss: 0.7159\n",
      "Average Discriminator Loss: 2.7465\n",
      "Checkpoint saved for epoch 15\n",
      "Generated sample image saved for epoch 15\n",
      "Epoch 16/50, Batch 1/50, Gen Loss: 0.6326 (L1: 0.2594, Perc: 0.5335, GAN: 19.3110), Disc Loss: 0.0000\n",
      "Epoch 16/50, Batch 11/50, Gen Loss: 0.8479 (L1: 0.3685, Perc: 0.6576, GAN: 37.3284), Disc Loss: 8.7877\n",
      "Epoch 16/50, Batch 21/50, Gen Loss: 0.5804 (L1: 0.2326, Perc: 0.4736, GAN: 20.8871), Disc Loss: 1.0657\n",
      "Epoch 16/50, Batch 31/50, Gen Loss: 0.5185 (L1: 0.2739, Perc: 0.4820, GAN: 6.7536), Disc Loss: 0.0012\n",
      "Epoch 16/50, Batch 41/50, Gen Loss: 0.5357 (L1: 0.2448, Perc: 0.3886, GAN: 28.9317), Disc Loss: 2.0414\n",
      "\n",
      "Epoch 16 Summary:\n",
      "Time: 15.44s\n",
      "Average Generator Loss: 0.7223\n",
      "Average Discriminator Loss: 3.7109\n",
      "Epoch 17/50, Batch 1/50, Gen Loss: 0.9227 (L1: 0.1811, Perc: 0.9209, GAN: 0.0022), Disc Loss: 7.5095\n",
      "Epoch 17/50, Batch 11/50, Gen Loss: 0.7489 (L1: 0.1406, Perc: 0.6514, GAN: 19.2142), Disc Loss: 0.0001\n",
      "Epoch 17/50, Batch 21/50, Gen Loss: 0.9846 (L1: 0.1920, Perc: 0.7514, GAN: 46.2573), Disc Loss: 0.5076\n",
      "Epoch 17/50, Batch 31/50, Gen Loss: 0.5004 (L1: 0.1039, Perc: 0.4994, GAN: 0.0002), Disc Loss: 8.4665\n",
      "Epoch 17/50, Batch 41/50, Gen Loss: 0.7438 (L1: 0.1118, Perc: 0.5773, GAN: 33.0809), Disc Loss: 3.0068\n",
      "\n",
      "Epoch 17 Summary:\n",
      "Time: 15.40s\n",
      "Average Generator Loss: 0.6908\n",
      "Average Discriminator Loss: 7.1675\n",
      "Epoch 18/50, Batch 1/50, Gen Loss: 0.3789 (L1: 0.1182, Perc: 0.3341, GAN: 8.7279), Disc Loss: 3.1583\n",
      "Epoch 18/50, Batch 11/50, Gen Loss: 0.7777 (L1: 0.1109, Perc: 0.5947, GAN: 36.3822), Disc Loss: 20.9652\n",
      "Epoch 18/50, Batch 21/50, Gen Loss: 0.7077 (L1: 0.1397, Perc: 0.6153, GAN: 18.2044), Disc Loss: 0.1113\n",
      "Epoch 18/50, Batch 31/50, Gen Loss: 0.7645 (L1: 0.1152, Perc: 0.6363, GAN: 25.3983), Disc Loss: 0.0000\n",
      "Epoch 18/50, Batch 41/50, Gen Loss: 1.0440 (L1: 0.1493, Perc: 0.7550, GAN: 57.4970), Disc Loss: 31.6943\n",
      "\n",
      "Epoch 18 Summary:\n",
      "Time: 15.45s\n",
      "Average Generator Loss: 0.6752\n",
      "Average Discriminator Loss: 5.8014\n",
      "Epoch 19/50, Batch 1/50, Gen Loss: 0.6065 (L1: 0.2438, Perc: 0.5159, GAN: 17.6306), Disc Loss: 0.0020\n",
      "Epoch 19/50, Batch 11/50, Gen Loss: 0.6478 (L1: 0.1634, Perc: 0.5661, GAN: 16.0099), Disc Loss: 1.8105\n",
      "Epoch 19/50, Batch 21/50, Gen Loss: 0.8697 (L1: 0.2620, Perc: 0.7943, GAN: 14.5537), Disc Loss: 0.0005\n",
      "Epoch 19/50, Batch 31/50, Gen Loss: 0.5587 (L1: 0.1578, Perc: 0.5114, GAN: 9.1480), Disc Loss: 0.2463\n",
      "Epoch 19/50, Batch 41/50, Gen Loss: 0.7443 (L1: 0.2532, Perc: 0.5683, GAN: 34.6951), Disc Loss: 18.1882\n",
      "\n",
      "Epoch 19 Summary:\n",
      "Time: 14.28s\n",
      "Average Generator Loss: 0.6864\n",
      "Average Discriminator Loss: 3.6293\n",
      "Epoch 20/50, Batch 1/50, Gen Loss: 1.2283 (L1: 0.2609, Perc: 0.7852, GAN: 88.0994), Disc Loss: 10.2290\n",
      "Epoch 20/50, Batch 11/50, Gen Loss: 0.6144 (L1: 0.0998, Perc: 0.6070, GAN: 1.2871), Disc Loss: 6.6222\n",
      "Epoch 20/50, Batch 21/50, Gen Loss: 0.5653 (L1: 0.1332, Perc: 0.4408, GAN: 24.6331), Disc Loss: 1.2712\n",
      "Epoch 20/50, Batch 31/50, Gen Loss: 0.5075 (L1: 0.1094, Perc: 0.3947, GAN: 22.3333), Disc Loss: 0.0028\n",
      "Epoch 20/50, Batch 41/50, Gen Loss: 0.5266 (L1: 0.1311, Perc: 0.4505, GAN: 14.9578), Disc Loss: 0.1638\n",
      "\n",
      "Epoch 20 Summary:\n",
      "Time: 14.73s\n",
      "Average Generator Loss: 0.6776\n",
      "Average Discriminator Loss: 3.1207\n",
      "Checkpoint saved for epoch 20\n",
      "Generated sample image saved for epoch 20\n",
      "Epoch 21/50, Batch 1/50, Gen Loss: 0.6500 (L1: 0.1044, Perc: 0.3973, GAN: 50.3329), Disc Loss: 4.7864\n",
      "Epoch 21/50, Batch 11/50, Gen Loss: 0.5544 (L1: 0.2613, Perc: 0.4648, GAN: 17.3897), Disc Loss: 0.0000\n",
      "Epoch 21/50, Batch 21/50, Gen Loss: 0.5381 (L1: 0.1454, Perc: 0.5334, GAN: 0.6641), Disc Loss: 6.0833\n",
      "Epoch 21/50, Batch 31/50, Gen Loss: 0.6044 (L1: 0.1321, Perc: 0.6031, GAN: 0.0000), Disc Loss: 29.6037\n",
      "Epoch 21/50, Batch 41/50, Gen Loss: 0.5432 (L1: 0.1005, Perc: 0.4836, GAN: 11.7114), Disc Loss: 0.3071\n",
      "\n",
      "Epoch 21 Summary:\n",
      "Time: 15.45s\n",
      "Average Generator Loss: 0.6904\n",
      "Average Discriminator Loss: 3.2624\n",
      "Epoch 22/50, Batch 1/50, Gen Loss: 1.0205 (L1: 0.1037, Perc: 0.8159, GAN: 40.7078), Disc Loss: 0.0000\n",
      "Epoch 22/50, Batch 11/50, Gen Loss: 0.4246 (L1: 0.1204, Perc: 0.4021, GAN: 4.2493), Disc Loss: 0.9607\n",
      "Epoch 22/50, Batch 21/50, Gen Loss: 0.5948 (L1: 0.1926, Perc: 0.4345, GAN: 31.6721), Disc Loss: 0.1673\n",
      "Epoch 22/50, Batch 31/50, Gen Loss: 0.6076 (L1: 0.1283, Perc: 0.5622, GAN: 8.8235), Disc Loss: 0.0002\n",
      "Epoch 22/50, Batch 41/50, Gen Loss: 0.7214 (L1: 0.1043, Perc: 0.6237, GAN: 19.3180), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 22 Summary:\n",
      "Time: 15.63s\n",
      "Average Generator Loss: 0.6667\n",
      "Average Discriminator Loss: 3.7049\n",
      "Epoch 23/50, Batch 1/50, Gen Loss: 0.6790 (L1: 0.1048, Perc: 0.5674, GAN: 22.1176), Disc Loss: 0.0000\n",
      "Epoch 23/50, Batch 11/50, Gen Loss: 0.5904 (L1: 0.1015, Perc: 0.4139, GAN: 35.1028), Disc Loss: 0.0015\n",
      "Epoch 23/50, Batch 21/50, Gen Loss: 0.7023 (L1: 0.0911, Perc: 0.5131, GAN: 37.6512), Disc Loss: 0.0000\n",
      "Epoch 23/50, Batch 31/50, Gen Loss: 0.7107 (L1: 0.1237, Perc: 0.5016, GAN: 41.5700), Disc Loss: 4.7978\n",
      "Epoch 23/50, Batch 41/50, Gen Loss: 0.4606 (L1: 0.1921, Perc: 0.4231, GAN: 7.1327), Disc Loss: 0.7259\n",
      "\n",
      "Epoch 23 Summary:\n",
      "Time: 15.47s\n",
      "Average Generator Loss: 0.6621\n",
      "Average Discriminator Loss: 2.3018\n",
      "Epoch 24/50, Batch 1/50, Gen Loss: 0.5721 (L1: 0.1215, Perc: 0.3802, GAN: 38.1463), Disc Loss: 10.7322\n",
      "Epoch 24/50, Batch 11/50, Gen Loss: 0.5254 (L1: 0.1476, Perc: 0.4882, GAN: 7.1451), Disc Loss: 0.6874\n",
      "Epoch 24/50, Batch 21/50, Gen Loss: 0.5833 (L1: 0.1315, Perc: 0.5208, GAN: 12.2503), Disc Loss: 0.9374\n",
      "Epoch 24/50, Batch 31/50, Gen Loss: 0.6930 (L1: 0.1050, Perc: 0.5296, GAN: 32.4544), Disc Loss: 7.2418\n",
      "Epoch 24/50, Batch 41/50, Gen Loss: 0.4012 (L1: 0.0876, Perc: 0.3833, GAN: 3.4013), Disc Loss: 0.4890\n",
      "\n",
      "Epoch 24 Summary:\n",
      "Time: 15.41s\n",
      "Average Generator Loss: 0.6435\n",
      "Average Discriminator Loss: 1.9362\n",
      "Epoch 25/50, Batch 1/50, Gen Loss: 0.7119 (L1: 0.1235, Perc: 0.6027, GAN: 21.5960), Disc Loss: 2.7860\n",
      "Epoch 25/50, Batch 11/50, Gen Loss: 0.5991 (L1: 0.1369, Perc: 0.5523, GAN: 9.0805), Disc Loss: 2.4202\n",
      "Epoch 25/50, Batch 21/50, Gen Loss: 0.6541 (L1: 0.0897, Perc: 0.4796, GAN: 34.7252), Disc Loss: 0.0001\n",
      "Epoch 25/50, Batch 31/50, Gen Loss: 0.4595 (L1: 0.1063, Perc: 0.4007, GAN: 11.5527), Disc Loss: 0.0452\n",
      "Epoch 25/50, Batch 41/50, Gen Loss: 0.5806 (L1: 0.1117, Perc: 0.4129, GAN: 33.3299), Disc Loss: 0.0001\n",
      "\n",
      "Epoch 25 Summary:\n",
      "Time: 15.43s\n",
      "Average Generator Loss: 0.6492\n",
      "Average Discriminator Loss: 2.8451\n",
      "Checkpoint saved for epoch 25\n",
      "Generated sample image saved for epoch 25\n",
      "Epoch 26/50, Batch 1/50, Gen Loss: 0.7234 (L1: 0.0754, Perc: 0.4714, GAN: 50.2458), Disc Loss: 3.1187\n",
      "Epoch 26/50, Batch 11/50, Gen Loss: 0.4708 (L1: 0.0692, Perc: 0.3841, GAN: 17.1979), Disc Loss: 0.0000\n",
      "Epoch 26/50, Batch 21/50, Gen Loss: 0.4585 (L1: 0.1080, Perc: 0.3851, GAN: 14.4783), Disc Loss: 0.0574\n",
      "Epoch 26/50, Batch 31/50, Gen Loss: 0.6238 (L1: 0.0663, Perc: 0.4984, GAN: 24.9524), Disc Loss: 0.0000\n",
      "Epoch 26/50, Batch 41/50, Gen Loss: 0.9089 (L1: 0.0782, Perc: 0.8105, GAN: 19.5179), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 26 Summary:\n",
      "Time: 15.51s\n",
      "Average Generator Loss: 0.6361\n",
      "Average Discriminator Loss: 2.6983\n",
      "Epoch 27/50, Batch 1/50, Gen Loss: 0.6090 (L1: 0.0930, Perc: 0.6017, GAN: 1.2653), Disc Loss: 6.8963\n",
      "Epoch 27/50, Batch 11/50, Gen Loss: 0.6984 (L1: 0.1730, Perc: 0.5768, GAN: 23.9772), Disc Loss: 0.0202\n",
      "Epoch 27/50, Batch 21/50, Gen Loss: 0.7703 (L1: 0.0779, Perc: 0.6457, GAN: 24.7576), Disc Loss: 0.0000\n",
      "Epoch 27/50, Batch 31/50, Gen Loss: 0.4922 (L1: 0.1133, Perc: 0.4316, GAN: 11.8933), Disc Loss: 0.0002\n",
      "Epoch 27/50, Batch 41/50, Gen Loss: 0.7889 (L1: 0.0825, Perc: 0.3810, GAN: 81.4268), Disc Loss: 9.0722\n",
      "\n",
      "Epoch 27 Summary:\n",
      "Time: 15.43s\n",
      "Average Generator Loss: 0.6533\n",
      "Average Discriminator Loss: 1.4525\n",
      "Epoch 28/50, Batch 1/50, Gen Loss: 0.7778 (L1: 0.1345, Perc: 0.7224, GAN: 10.8149), Disc Loss: 5.3893\n",
      "Epoch 28/50, Batch 11/50, Gen Loss: 0.6051 (L1: 0.0898, Perc: 0.5223, GAN: 16.3915), Disc Loss: 0.0000\n",
      "Epoch 28/50, Batch 21/50, Gen Loss: 0.6327 (L1: 0.1084, Perc: 0.4991, GAN: 26.4942), Disc Loss: 0.0001\n",
      "Epoch 28/50, Batch 31/50, Gen Loss: 0.4251 (L1: 0.0936, Perc: 0.2966, GAN: 25.5067), Disc Loss: 0.0000\n",
      "Epoch 28/50, Batch 41/50, Gen Loss: 0.5619 (L1: 0.1670, Perc: 0.4821, GAN: 15.6144), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 28 Summary:\n",
      "Time: 15.41s\n",
      "Average Generator Loss: 0.6498\n",
      "Average Discriminator Loss: 0.7896\n",
      "Epoch 29/50, Batch 1/50, Gen Loss: 0.4793 (L1: 0.1165, Perc: 0.3673, GAN: 22.1546), Disc Loss: 0.0000\n",
      "Epoch 29/50, Batch 11/50, Gen Loss: 0.9404 (L1: 0.1490, Perc: 0.5238, GAN: 83.0223), Disc Loss: 0.0028\n",
      "Epoch 29/50, Batch 21/50, Gen Loss: 0.6993 (L1: 0.1912, Perc: 0.6309, GAN: 13.2938), Disc Loss: 0.0007\n",
      "Epoch 29/50, Batch 31/50, Gen Loss: 0.5135 (L1: 0.1211, Perc: 0.4733, GAN: 7.7985), Disc Loss: 0.4641\n",
      "Epoch 29/50, Batch 41/50, Gen Loss: 0.7438 (L1: 0.1304, Perc: 0.5479, GAN: 38.9199), Disc Loss: 0.1348\n",
      "\n",
      "Epoch 29 Summary:\n",
      "Time: 15.50s\n",
      "Average Generator Loss: 0.6465\n",
      "Average Discriminator Loss: 0.5394\n",
      "Epoch 30/50, Batch 1/50, Gen Loss: 0.6370 (L1: 0.1474, Perc: 0.5076, GAN: 25.5768), Disc Loss: 0.9290\n",
      "Epoch 30/50, Batch 11/50, Gen Loss: 0.6248 (L1: 0.1445, Perc: 0.5392, GAN: 16.8417), Disc Loss: 0.0000\n",
      "Epoch 30/50, Batch 21/50, Gen Loss: 0.6511 (L1: 0.1000, Perc: 0.5474, GAN: 20.5318), Disc Loss: 0.3804\n",
      "Epoch 30/50, Batch 31/50, Gen Loss: 0.5503 (L1: 0.1392, Perc: 0.4110, GAN: 27.5858), Disc Loss: 0.7625\n",
      "Epoch 30/50, Batch 41/50, Gen Loss: 0.5054 (L1: 0.1278, Perc: 0.3153, GAN: 37.7562), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 30 Summary:\n",
      "Time: 15.40s\n",
      "Average Generator Loss: 0.6566\n",
      "Average Discriminator Loss: 0.4762\n",
      "Checkpoint saved for epoch 30\n",
      "Generated sample image saved for epoch 30\n",
      "Epoch 31/50, Batch 1/50, Gen Loss: 0.7795 (L1: 0.1420, Perc: 0.6417, GAN: 27.2821), Disc Loss: 2.7596\n",
      "Epoch 31/50, Batch 11/50, Gen Loss: 0.5954 (L1: 0.1062, Perc: 0.5274, GAN: 13.3822), Disc Loss: 0.0252\n",
      "Epoch 31/50, Batch 21/50, Gen Loss: 0.8517 (L1: 0.2383, Perc: 0.7220, GAN: 25.4664), Disc Loss: 0.5314\n",
      "Epoch 31/50, Batch 31/50, Gen Loss: 0.6173 (L1: 0.1071, Perc: 0.5122, GAN: 20.8066), Disc Loss: 0.0000\n",
      "Epoch 31/50, Batch 41/50, Gen Loss: 0.7711 (L1: 0.1899, Perc: 0.5444, GAN: 44.9723), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 31 Summary:\n",
      "Time: 14.88s\n",
      "Average Generator Loss: 0.6482\n",
      "Average Discriminator Loss: 0.4243\n",
      "Epoch 32/50, Batch 1/50, Gen Loss: 0.7584 (L1: 0.1343, Perc: 0.6277, GAN: 25.8748), Disc Loss: 0.0000\n",
      "Epoch 32/50, Batch 11/50, Gen Loss: 0.4706 (L1: 0.1350, Perc: 0.3613, GAN: 21.5880), Disc Loss: 0.0000\n",
      "Epoch 32/50, Batch 21/50, Gen Loss: 0.7174 (L1: 0.1856, Perc: 0.6272, GAN: 17.6633), Disc Loss: 0.0023\n",
      "Epoch 32/50, Batch 31/50, Gen Loss: 0.7503 (L1: 0.0818, Perc: 0.5758, GAN: 34.7540), Disc Loss: 0.0000\n",
      "Epoch 32/50, Batch 41/50, Gen Loss: 0.8251 (L1: 0.1248, Perc: 0.5940, GAN: 45.9762), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 32 Summary:\n",
      "Time: 14.21s\n",
      "Average Generator Loss: 0.6569\n",
      "Average Discriminator Loss: 0.3460\n",
      "Epoch 33/50, Batch 1/50, Gen Loss: 0.5511 (L1: 0.1023, Perc: 0.4644, GAN: 17.1305), Disc Loss: 0.0000\n",
      "Epoch 33/50, Batch 11/50, Gen Loss: 0.5700 (L1: 0.1378, Perc: 0.4835, GAN: 17.0247), Disc Loss: 0.0000\n",
      "Epoch 33/50, Batch 21/50, Gen Loss: 0.5298 (L1: 0.1516, Perc: 0.3979, GAN: 26.0890), Disc Loss: 0.0000\n",
      "Epoch 33/50, Batch 31/50, Gen Loss: 0.6865 (L1: 0.1319, Perc: 0.5304, GAN: 30.9502), Disc Loss: 0.0011\n",
      "Epoch 33/50, Batch 41/50, Gen Loss: 0.5671 (L1: 0.1063, Perc: 0.3905, GAN: 35.0942), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 33 Summary:\n",
      "Time: 13.99s\n",
      "Average Generator Loss: 0.6585\n",
      "Average Discriminator Loss: 0.7099\n",
      "Epoch 34/50, Batch 1/50, Gen Loss: 0.8206 (L1: 0.1489, Perc: 0.7207, GAN: 19.6952), Disc Loss: 0.0130\n",
      "Epoch 34/50, Batch 11/50, Gen Loss: 0.7046 (L1: 0.1351, Perc: 0.5563, GAN: 29.3889), Disc Loss: 0.0000\n",
      "Epoch 34/50, Batch 21/50, Gen Loss: 0.4934 (L1: 0.0887, Perc: 0.3577, GAN: 26.9691), Disc Loss: 0.0000\n",
      "Epoch 34/50, Batch 31/50, Gen Loss: 0.7828 (L1: 0.1369, Perc: 0.5864, GAN: 39.0128), Disc Loss: 0.0000\n",
      "Epoch 34/50, Batch 41/50, Gen Loss: 0.6669 (L1: 0.1065, Perc: 0.4583, GAN: 41.5008), Disc Loss: 0.0015\n",
      "\n",
      "Epoch 34 Summary:\n",
      "Time: 14.15s\n",
      "Average Generator Loss: 0.6627\n",
      "Average Discriminator Loss: 0.5172\n",
      "Epoch 35/50, Batch 1/50, Gen Loss: 0.5549 (L1: 0.1455, Perc: 0.4499, GAN: 20.6916), Disc Loss: 0.0007\n",
      "Epoch 35/50, Batch 11/50, Gen Loss: 0.7171 (L1: 0.1011, Perc: 0.5877, GAN: 25.6838), Disc Loss: 0.0000\n",
      "Epoch 35/50, Batch 21/50, Gen Loss: 0.6101 (L1: 0.1377, Perc: 0.5206, GAN: 17.6274), Disc Loss: 0.0000\n",
      "Epoch 35/50, Batch 31/50, Gen Loss: 0.8072 (L1: 0.0788, Perc: 0.3479, GAN: 91.6936), Disc Loss: 0.0000\n",
      "Epoch 35/50, Batch 41/50, Gen Loss: 0.5330 (L1: 0.1092, Perc: 0.3707, GAN: 32.2474), Disc Loss: 0.0001\n",
      "\n",
      "Epoch 35 Summary:\n",
      "Time: 15.51s\n",
      "Average Generator Loss: 0.6611\n",
      "Average Discriminator Loss: 0.1030\n",
      "Checkpoint saved for epoch 35\n",
      "Generated sample image saved for epoch 35\n",
      "Epoch 36/50, Batch 1/50, Gen Loss: 0.7404 (L1: 0.1242, Perc: 0.5153, GAN: 44.7541), Disc Loss: 0.0000\n",
      "Epoch 36/50, Batch 11/50, Gen Loss: 0.6052 (L1: 0.1072, Perc: 0.4556, GAN: 29.7199), Disc Loss: 0.0001\n",
      "Epoch 36/50, Batch 21/50, Gen Loss: 0.4550 (L1: 0.1064, Perc: 0.3405, GAN: 22.6864), Disc Loss: 0.0000\n",
      "Epoch 36/50, Batch 31/50, Gen Loss: 0.8484 (L1: 0.0934, Perc: 0.5620, GAN: 57.0880), Disc Loss: 0.0000\n",
      "Epoch 36/50, Batch 41/50, Gen Loss: 0.3776 (L1: 0.1115, Perc: 0.3119, GAN: 12.9062), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 36 Summary:\n",
      "Time: 15.50s\n",
      "Average Generator Loss: 0.6369\n",
      "Average Discriminator Loss: 0.1328\n",
      "Epoch 37/50, Batch 1/50, Gen Loss: 0.8548 (L1: 0.1130, Perc: 0.7287, GAN: 25.0022), Disc Loss: 0.0003\n",
      "Epoch 37/50, Batch 11/50, Gen Loss: 0.5144 (L1: 0.1209, Perc: 0.2966, GAN: 43.3274), Disc Loss: 0.0004\n",
      "Epoch 37/50, Batch 21/50, Gen Loss: 0.4414 (L1: 0.1086, Perc: 0.4138, GAN: 5.2881), Disc Loss: 0.1254\n",
      "Epoch 37/50, Batch 31/50, Gen Loss: 0.8538 (L1: 0.0851, Perc: 0.7150, GAN: 27.5904), Disc Loss: 0.0000\n",
      "Epoch 37/50, Batch 41/50, Gen Loss: 0.5882 (L1: 0.0924, Perc: 0.5438, GAN: 8.7032), Disc Loss: 0.0193\n",
      "\n",
      "Epoch 37 Summary:\n",
      "Time: 15.51s\n",
      "Average Generator Loss: 0.6384\n",
      "Average Discriminator Loss: 0.0576\n",
      "Epoch 38/50, Batch 1/50, Gen Loss: 0.6645 (L1: 0.1028, Perc: 0.5449, GAN: 23.7240), Disc Loss: 0.0000\n",
      "Epoch 38/50, Batch 11/50, Gen Loss: 0.6218 (L1: 0.1279, Perc: 0.5030, GAN: 23.4967), Disc Loss: 0.0000\n",
      "Epoch 38/50, Batch 21/50, Gen Loss: 0.5713 (L1: 0.1029, Perc: 0.4085, GAN: 32.3445), Disc Loss: 0.0001\n",
      "Epoch 38/50, Batch 31/50, Gen Loss: 0.4858 (L1: 0.1181, Perc: 0.3550, GAN: 25.9263), Disc Loss: 0.0000\n",
      "Epoch 38/50, Batch 41/50, Gen Loss: 0.6767 (L1: 0.0932, Perc: 0.5010, GAN: 34.9606), Disc Loss: 0.0001\n",
      "\n",
      "Epoch 38 Summary:\n",
      "Time: 15.44s\n",
      "Average Generator Loss: 0.6726\n",
      "Average Discriminator Loss: 0.1923\n",
      "Epoch 39/50, Batch 1/50, Gen Loss: 0.8290 (L1: 0.0834, Perc: 0.5984, GAN: 45.9526), Disc Loss: 0.0000\n",
      "Epoch 39/50, Batch 11/50, Gen Loss: 0.8651 (L1: 0.1104, Perc: 0.7357, GAN: 25.6505), Disc Loss: 0.0000\n",
      "Epoch 39/50, Batch 21/50, Gen Loss: 0.4992 (L1: 0.0848, Perc: 0.3867, GAN: 22.3232), Disc Loss: 0.0000\n",
      "Epoch 39/50, Batch 31/50, Gen Loss: 0.5057 (L1: 0.0800, Perc: 0.4067, GAN: 19.6455), Disc Loss: 0.0000\n",
      "Epoch 39/50, Batch 41/50, Gen Loss: 0.5961 (L1: 0.1418, Perc: 0.3957, GAN: 39.7810), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 39 Summary:\n",
      "Time: 15.38s\n",
      "Average Generator Loss: 0.6870\n",
      "Average Discriminator Loss: 0.1641\n",
      "Epoch 40/50, Batch 1/50, Gen Loss: 0.7611 (L1: 0.0612, Perc: 0.5471, GAN: 42.6786), Disc Loss: 0.0000\n",
      "Epoch 40/50, Batch 11/50, Gen Loss: 0.7010 (L1: 0.1107, Perc: 0.5523, GAN: 29.5156), Disc Loss: 0.0000\n",
      "Epoch 40/50, Batch 21/50, Gen Loss: 0.7371 (L1: 0.0922, Perc: 0.5592, GAN: 35.3933), Disc Loss: 0.0023\n",
      "Epoch 40/50, Batch 31/50, Gen Loss: 0.7267 (L1: 0.1010, Perc: 0.6630, GAN: 12.5374), Disc Loss: 1.1935\n",
      "Epoch 40/50, Batch 41/50, Gen Loss: 0.6037 (L1: 0.0819, Perc: 0.4209, GAN: 36.4066), Disc Loss: 1.1821\n",
      "\n",
      "Epoch 40 Summary:\n",
      "Time: 14.98s\n",
      "Average Generator Loss: 0.6825\n",
      "Average Discriminator Loss: 0.0543\n",
      "Checkpoint saved for epoch 40\n",
      "Generated sample image saved for epoch 40\n",
      "Epoch 41/50, Batch 1/50, Gen Loss: 0.7270 (L1: 0.0892, Perc: 0.4695, GAN: 51.3305), Disc Loss: 0.0006\n",
      "Epoch 41/50, Batch 11/50, Gen Loss: 0.4425 (L1: 0.0765, Perc: 0.3226, GAN: 23.8373), Disc Loss: 0.0000\n",
      "Epoch 41/50, Batch 21/50, Gen Loss: 0.3922 (L1: 0.0738, Perc: 0.2924, GAN: 19.8212), Disc Loss: 0.0000\n",
      "Epoch 41/50, Batch 31/50, Gen Loss: 0.6103 (L1: 0.1096, Perc: 0.4531, GAN: 31.2301), Disc Loss: 0.0000\n",
      "Epoch 41/50, Batch 41/50, Gen Loss: 0.6996 (L1: 0.0934, Perc: 0.3918, GAN: 61.3655), Disc Loss: 0.0879\n",
      "\n",
      "Epoch 41 Summary:\n",
      "Time: 14.05s\n",
      "Average Generator Loss: 0.6640\n",
      "Average Discriminator Loss: 0.6206\n",
      "Epoch 42/50, Batch 1/50, Gen Loss: 0.8779 (L1: 0.0794, Perc: 0.6760, GAN: 40.2143), Disc Loss: 0.0000\n",
      "Epoch 42/50, Batch 11/50, Gen Loss: 0.5859 (L1: 0.1174, Perc: 0.4872, GAN: 19.4990), Disc Loss: 0.0000\n",
      "Epoch 42/50, Batch 21/50, Gen Loss: 1.0605 (L1: 0.1157, Perc: 0.4955, GAN: 112.7716), Disc Loss: 2.9438\n",
      "Epoch 42/50, Batch 31/50, Gen Loss: 0.4294 (L1: 0.0977, Perc: 0.3606, GAN: 13.5629), Disc Loss: 0.0016\n",
      "Epoch 42/50, Batch 41/50, Gen Loss: 0.4329 (L1: 0.0840, Perc: 0.3144, GAN: 23.5188), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 42 Summary:\n",
      "Time: 14.27s\n",
      "Average Generator Loss: 0.6847\n",
      "Average Discriminator Loss: 0.2516\n",
      "Epoch 43/50, Batch 1/50, Gen Loss: 0.6721 (L1: 0.1100, Perc: 0.5557, GAN: 23.0547), Disc Loss: 0.0000\n",
      "Epoch 43/50, Batch 11/50, Gen Loss: 0.8042 (L1: 0.1035, Perc: 0.4490, GAN: 70.8346), Disc Loss: 0.0000\n",
      "Epoch 43/50, Batch 21/50, Gen Loss: 0.4947 (L1: 0.1007, Perc: 0.3404, GAN: 30.6631), Disc Loss: 0.0000\n",
      "Epoch 43/50, Batch 31/50, Gen Loss: 0.5197 (L1: 0.0844, Perc: 0.4118, GAN: 21.3987), Disc Loss: 5.1567\n",
      "Epoch 43/50, Batch 41/50, Gen Loss: 0.4593 (L1: 0.0945, Perc: 0.3497, GAN: 21.7203), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 43 Summary:\n",
      "Time: 15.33s\n",
      "Average Generator Loss: 0.6692\n",
      "Average Discriminator Loss: 0.1267\n",
      "Epoch 44/50, Batch 1/50, Gen Loss: 0.5174 (L1: 0.1315, Perc: 0.3977, GAN: 23.6898), Disc Loss: 0.0000\n",
      "Epoch 44/50, Batch 11/50, Gen Loss: 0.5184 (L1: 0.0741, Perc: 0.3854, GAN: 26.4465), Disc Loss: 0.0000\n",
      "Epoch 44/50, Batch 21/50, Gen Loss: 0.7325 (L1: 0.1189, Perc: 0.4693, GAN: 52.3959), Disc Loss: 0.0000\n",
      "Epoch 44/50, Batch 31/50, Gen Loss: 0.7633 (L1: 0.1061, Perc: 0.5788, GAN: 36.7044), Disc Loss: 0.0000\n",
      "Epoch 44/50, Batch 41/50, Gen Loss: 1.0169 (L1: 0.0749, Perc: 0.3364, GAN: 135.9487), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 44 Summary:\n",
      "Time: 15.42s\n",
      "Average Generator Loss: 0.6545\n",
      "Average Discriminator Loss: 0.1745\n",
      "Epoch 45/50, Batch 1/50, Gen Loss: 0.5980 (L1: 0.0730, Perc: 0.4697, GAN: 25.5216), Disc Loss: 0.0000\n",
      "Epoch 45/50, Batch 11/50, Gen Loss: 0.6796 (L1: 0.1164, Perc: 0.4737, GAN: 40.9546), Disc Loss: 0.0000\n",
      "Epoch 45/50, Batch 21/50, Gen Loss: 0.6798 (L1: 0.0926, Perc: 0.4740, GAN: 40.9748), Disc Loss: 0.0000\n",
      "Epoch 45/50, Batch 31/50, Gen Loss: 0.5896 (L1: 0.1077, Perc: 0.3511, GAN: 47.5015), Disc Loss: 0.0000\n",
      "Epoch 45/50, Batch 41/50, Gen Loss: 0.8456 (L1: 0.0722, Perc: 0.7861, GAN: 11.7424), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 45 Summary:\n",
      "Time: 15.45s\n",
      "Average Generator Loss: 0.6530\n",
      "Average Discriminator Loss: 0.4100\n",
      "Checkpoint saved for epoch 45\n",
      "Generated sample image saved for epoch 45\n",
      "Epoch 46/50, Batch 1/50, Gen Loss: 0.5539 (L1: 0.0918, Perc: 0.4568, GAN: 19.2274), Disc Loss: 0.0000\n",
      "Epoch 46/50, Batch 11/50, Gen Loss: 0.8921 (L1: 0.1512, Perc: 0.7005, GAN: 38.0282), Disc Loss: 0.0000\n",
      "Epoch 46/50, Batch 21/50, Gen Loss: 0.5461 (L1: 0.0939, Perc: 0.3870, GAN: 31.6263), Disc Loss: 0.0023\n",
      "Epoch 46/50, Batch 31/50, Gen Loss: 0.8367 (L1: 0.0999, Perc: 0.6761, GAN: 31.9294), Disc Loss: 0.0001\n",
      "Epoch 46/50, Batch 41/50, Gen Loss: 0.7582 (L1: 0.1239, Perc: 0.5415, GAN: 43.0863), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 46 Summary:\n",
      "Time: 15.31s\n",
      "Average Generator Loss: 0.6975\n",
      "Average Discriminator Loss: 0.0005\n",
      "Epoch 47/50, Batch 1/50, Gen Loss: 0.7718 (L1: 0.1551, Perc: 0.6314, GAN: 27.7720), Disc Loss: 0.0000\n",
      "Epoch 47/50, Batch 11/50, Gen Loss: 0.6498 (L1: 0.1223, Perc: 0.4830, GAN: 33.1233), Disc Loss: 0.0012\n",
      "Epoch 47/50, Batch 21/50, Gen Loss: 0.7345 (L1: 0.1553, Perc: 0.4020, GAN: 66.1943), Disc Loss: 0.0000\n",
      "Epoch 47/50, Batch 31/50, Gen Loss: 0.5124 (L1: 0.0901, Perc: 0.3728, GAN: 27.7396), Disc Loss: 0.0000\n",
      "Epoch 47/50, Batch 41/50, Gen Loss: 0.6182 (L1: 0.1095, Perc: 0.4736, GAN: 28.7026), Disc Loss: 0.0001\n",
      "\n",
      "Epoch 47 Summary:\n",
      "Time: 15.24s\n",
      "Average Generator Loss: 0.6743\n",
      "Average Discriminator Loss: 0.0005\n",
      "Epoch 48/50, Batch 1/50, Gen Loss: 0.5775 (L1: 0.1146, Perc: 0.4686, GAN: 21.5628), Disc Loss: 0.0001\n",
      "Epoch 48/50, Batch 11/50, Gen Loss: 0.7283 (L1: 0.0914, Perc: 0.4728, GAN: 50.9092), Disc Loss: 0.0000\n",
      "Epoch 48/50, Batch 21/50, Gen Loss: 0.6780 (L1: 0.1496, Perc: 0.5414, GAN: 27.0124), Disc Loss: 0.0000\n",
      "Epoch 48/50, Batch 31/50, Gen Loss: 0.6480 (L1: 0.0976, Perc: 0.5161, GAN: 26.1923), Disc Loss: 0.0000\n",
      "Epoch 48/50, Batch 41/50, Gen Loss: 0.7287 (L1: 0.1491, Perc: 0.5379, GAN: 37.8644), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 48 Summary:\n",
      "Time: 15.25s\n",
      "Average Generator Loss: 0.6532\n",
      "Average Discriminator Loss: 0.0002\n",
      "Epoch 49/50, Batch 1/50, Gen Loss: 0.7970 (L1: 0.1246, Perc: 0.6574, GAN: 27.6561), Disc Loss: 0.0004\n",
      "Epoch 49/50, Batch 11/50, Gen Loss: 0.5950 (L1: 0.0926, Perc: 0.3583, GAN: 47.1666), Disc Loss: 0.0000\n",
      "Epoch 49/50, Batch 21/50, Gen Loss: 0.5343 (L1: 0.0916, Perc: 0.4039, GAN: 25.8944), Disc Loss: 0.0000\n",
      "Epoch 49/50, Batch 31/50, Gen Loss: 0.5760 (L1: 0.1174, Perc: 0.3849, GAN: 37.9983), Disc Loss: 0.0011\n",
      "Epoch 49/50, Batch 41/50, Gen Loss: 0.6141 (L1: 0.1259, Perc: 0.5085, GAN: 20.8760), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 49 Summary:\n",
      "Time: 14.97s\n",
      "Average Generator Loss: 0.6592\n",
      "Average Discriminator Loss: 0.0025\n",
      "Epoch 50/50, Batch 1/50, Gen Loss: 0.7357 (L1: 0.0979, Perc: 0.5991, GAN: 27.1137), Disc Loss: 0.0000\n",
      "Epoch 50/50, Batch 11/50, Gen Loss: 0.9559 (L1: 0.1423, Perc: 0.7642, GAN: 38.0377), Disc Loss: 0.0001\n",
      "Epoch 50/50, Batch 21/50, Gen Loss: 0.8270 (L1: 0.1378, Perc: 0.5943, GAN: 46.2668), Disc Loss: 0.0000\n",
      "Epoch 50/50, Batch 31/50, Gen Loss: 0.6032 (L1: 0.0749, Perc: 0.3203, GAN: 56.4268), Disc Loss: 0.0000\n",
      "Epoch 50/50, Batch 41/50, Gen Loss: 0.6105 (L1: 0.1090, Perc: 0.4841, GAN: 25.0644), Disc Loss: 0.0000\n",
      "\n",
      "Epoch 50 Summary:\n",
      "Time: 15.30s\n",
      "Average Generator Loss: 0.6567\n",
      "Average Discriminator Loss: 0.0023\n",
      "Checkpoint saved for epoch 50\n",
      "Generated sample image saved for epoch 50\n",
      "\n",
      "--- Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58c81b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
